app_overview: "This example application demonstrates a multimodal Retrieval Augmented Generation (RAG) Pipeline.\n\n\ 
  \ Enabling users to load images or PDF files, and receive answers to questions about their contents. \n\n \
  \ This pipeline will process the documents, extracting Text, Table and images, \
  \ and then generates summaries of each. Next the summaries are stored in a multi vector vectorstore. \n\n\
  \ When a query is submitted the raw relevant content is retrieved based on summary similarity, the retrieved contents are processed \
  \ individually among the user query (for retrieved images by the multimodal model), \
  \ The intermediate responses are used to refine a final answer which is generated by the LLM. \n\n\
  \ This application also has conversational capabilities, allowing users to engage in a dialogue with the system. \
  \ In each turn the user's query is reformulated and refined based on the previous conversation history. \n\n \
  \ \\* *Creating text and table summaries is optional, if not selected in the setup bar the raw text \
  \ and extracted HTML tables will be used*"